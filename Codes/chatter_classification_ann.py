# -*- coding: utf-8 -*-
"""chatter_classification_ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PHUC9vbPCSDkM4mFwhbex9WollynXvjL
"""

from google.colab import drive
drive.mount("drive", force_remount = False)

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import sklearn
from sklearn.model_selection import train_test_split
import scipy
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
import random
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from statistics import median
from keras.preprocessing.sequence import pad_sequences
from sklearn import metrics

path = "drive/MyDrive/classification_dataset_no_vif.csv"
dfn = pd.read_csv(path)

path = "drive/MyDrive/classification_dataset_vif.csv"
dfv = pd.read_csv(path)

def func(df):
  X = df.iloc[:,:-1]
  y = df.iloc[:,-1]
  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 101)
  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size = 0.8, random_state = 101)
  minmax = MinMaxScaler(feature_range = (0,1))
  minmax.fit(X_train.iloc[:, 9:])
  X_train.iloc[:, 9:] = minmax.transform(X_train.iloc[:, 9:])
  X_val.iloc[:, 9:] = minmax.transform(X_val.iloc[:, 9:])
  X_test.iloc[:, 9:] = minmax.transform(X_test.iloc[:, 9:])
  X_train = X_train.values
  X_val = X_val.values
  X_test = X_test.values
  y_train = y_train.values
  y_val = y_val.values
  y_test = y_test.values
  return X_train, X_val, X_test, y_train, y_val, y_test

X_train, X_val, X_test, y_train, y_val, y_test = func(dfn)

print(X_train.shape)
print(X_val.shape)
print(X_test.shape)
print(y_train.shape)
print(y_val.shape)
print(y_test.shape)

y_test

"""# Defining the Artificial Neural Network using keras"""

model = Sequential()
model.add(Dense(40, input_dim = 393, activation = "relu", kernel_regularizer = "l1"))
model.add(Dropout(0.3))
model.add(Dense(10, activation = "relu", kernel_regularizer = "l1"))
model.add(Dropout(0.1))
model.add(Dense(4, activation = "softmax"))

"""# Compiling the model"""

model.compile(loss = "sparse_categorical_crossentropy", optimizer = "adam", metrics = ["accuracy"])

"""# Fitting the model"""

history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, verbose=0)

"""# Evaluatiing the model"""

_, train_acc = model.evaluate(X_train, y_train, verbose=0)
_, val_acc = model.evaluate(X_val, y_val, verbose = 0)
_, test_acc = model.evaluate(X_test, y_test, verbose=0)
print('Train: %.3f, Val: %.3f, Test: %.3f' % (train_acc, val_acc, test_acc))

"""#Plotting loss during training"""

plt.figure(figsize = (10,10))
plt.subplot(211)
plt.title('Loss')
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='val')
plt.legend()

"""# Plotting accuracy during training"""

plt.figure(figsize = (10,10))
plt.subplot(212)
plt.title('Accuracy')
plt.plot(history.history['accuracy'], label='train')
plt.plot(history.history['val_accuracy'], label='val')
plt.legend()

y_pred = model.predict(X_test)

y_pred>0.5

